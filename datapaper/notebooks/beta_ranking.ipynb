{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9f8c056",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05dfc09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os, sys, json\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acf10de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version:  1.21.2\n",
      "pandas version:  1.3.2\n",
      "matplotlib version:  3.5.0\n",
      "seaborn version:  0.11.0\n"
     ]
    }
   ],
   "source": [
    "print('numpy version: ', np.__version__)\n",
    "print('pandas version: ', pd.__version__)\n",
    "print('matplotlib version: ', mpl.__version__)\n",
    "print('seaborn version: ', sns.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aac2dd",
   "metadata": {},
   "source": [
    "# Beta Ranking Analyses \n",
    "\n",
    "This notebook includes the code used to generate color-coded rankings of beta weights from Figure 5. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd3fdd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define support functions to build a DataFrame of image labels\n",
    "\"\"\"\n",
    "def cap_vals(row, value, cap):\n",
    "    if row[value] > cap:\n",
    "        return cap\n",
    "    else:\n",
    "        return row[value]\n",
    "    \n",
    "    \n",
    "def label_cft(row):\n",
    "    grp_val = row['cfpt']\n",
    "    if grp_val == 3:\n",
    "        return '1. human face'\n",
    "    elif grp_val == 2:\n",
    "        return '2. mammal face'\n",
    "    elif grp_val == 1:\n",
    "        return '3. other face'\n",
    "    elif grp_val == 0:\n",
    "        return '4. no face'\n",
    "\n",
    "    \n",
    "def label_clt(row):\n",
    "    grp_val = row['clpt']\n",
    "    if grp_val >= 3:\n",
    "        return '1. human'\n",
    "    elif grp_val == 2:\n",
    "        return '2. mammal'\n",
    "    elif grp_val == 1:\n",
    "        return '3. other living thing'\n",
    "    elif grp_val == 0:\n",
    "        return '4. no living thing'\n",
    "\n",
    "    \n",
    "def label_cbt(row):\n",
    "    grp_val = row['cbpt']\n",
    "    if grp_val >= 3:\n",
    "        return '1. human body'\n",
    "    elif grp_val == 2:\n",
    "        return '2. mammal body'\n",
    "    elif grp_val == 1:\n",
    "        return '3. other living body'\n",
    "    elif grp_val == 0:\n",
    "        return '4. no living body'\n",
    "\n",
    "    \n",
    "def label_bkpt(row):\n",
    "    grp_val = row['bkpt']\n",
    "    if grp_val >= 3:\n",
    "        return '1. scene'\n",
    "    elif grp_val == 2:\n",
    "        return '2. rich background'\n",
    "    elif grp_val == 1:\n",
    "        return '3. minimum background'\n",
    "    elif grp_val == 0:\n",
    "        return '4. no background'\n",
    "    \n",
    "    \n",
    "def label_rf(row):\n",
    "    grp_val = row['chfrf']\n",
    "    if grp_val == 2:\n",
    "        return '1. natural human face'\n",
    "    elif grp_val == 1:\n",
    "        return '2. artificial human face'\n",
    "    elif grp_val == 0:\n",
    "        return '3. no human face'\n",
    "    \n",
    "\n",
    "def generate_data(\n",
    "    beta_idx: np.array,\n",
    "    img_idx: np.array,\n",
    "    ranked_betas: np.array,\n",
    "    img_details: dict,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Builds DataFrame of betas, image labels and annotations to plot ranked betas\n",
    "    \"\"\"\n",
    "    df_2plot = pd.DataFrame(ranked_betas, columns=['betas'])\n",
    "    #pic_names = [img_idx[x] for x in beta_idx]\n",
    "\n",
    "    \"\"\"\n",
    "    Face stuff\n",
    "    \"\"\"\n",
    "    is_face = np.array([img_details[img_idx[x]]['manual_face'] for x in beta_idx])\n",
    "    is_human_face = np.array([img_details[img_idx[x]]['manual_human_face'] for x in beta_idx])\n",
    "    is_nh_mammal_face = np.array([img_details[img_idx[x]]['manual_nh_mammal_face'] for x in beta_idx])\n",
    "    is_central_face = np.array([img_details[img_idx[x]]['manual_central_face'] for x in beta_idx])\n",
    "    is_artificial_face = np.array([img_details[img_idx[x]]['manual_artificial_face'] for x in beta_idx])\n",
    "\n",
    "    df_2plot['is_face'] = is_face.astype(bool)\n",
    "    df_2plot['is_central_face'] = is_central_face.astype(bool)\n",
    "    df_2plot['is_noncentral_face'] = (is_face*(is_central_face==0)).astype(bool)\n",
    "    df_2plot['is_human_face'] = is_human_face.astype(bool)\n",
    "    df_2plot['is_central_human_face'] = (is_human_face*is_central_face).astype(bool)\n",
    "    df_2plot['is_noncentral_human_face'] = (is_human_face*(is_central_face==0)).astype(bool)\n",
    "    df_2plot['is_central_mammal_face'] = ((is_human_face*is_central_face)+(is_nh_mammal_face*is_central_face)).astype(bool)\n",
    "\n",
    "    # levels: central face that is human (3), nh_mammal (2), or something else (1)\n",
    "    df_2plot['cfpt'] = (is_central_face + (2*(is_central_face*is_human_face)) + (is_central_face*is_nh_mammal_face)).astype(int)\n",
    "    df_2plot['cfpt'] = df_2plot.apply(lambda row: cap_vals(row, 'cfpt', 3), axis=1)\n",
    "    df_2plot['central_face_per_type'] = df_2plot.apply(lambda row: label_cft(row), axis=1)\n",
    "\n",
    "    # levels: central human face that is natural (2) or artificial (1)\n",
    "    df_2plot['chfrf'] = (((is_human_face*is_central_face)*2) - (is_human_face*is_central_face*is_artificial_face)).astype(int)\n",
    "    df_2plot['chfrf'] = df_2plot.apply(lambda row: cap_vals(row, 'chfrf', 3), axis=1)\n",
    "    df_2plot['central_human_face_realORfake'] = df_2plot.apply(lambda row: label_rf(row), axis=1)\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Body stuff\n",
    "    \"\"\"\n",
    "    has_body = np.array([img_details[img_idx[x]]['manual_body'] for x in beta_idx])\n",
    "    has_human_body = np.array([img_details[img_idx[x]]['manual_human_body'] for x in beta_idx])\n",
    "    has_nh_mammal_body = np.array([img_details[img_idx[x]]['manual_nh_mammal_body'] for x in beta_idx])\n",
    "    has_central_body = np.array([img_details[img_idx[x]]['manual_central_body'] for x in beta_idx])\n",
    "    has_artificial_body = np.array([img_details[img_idx[x]]['manual_artificial_body'] for x in beta_idx])\n",
    "\n",
    "    df_2plot['has_body'] = has_body.astype(bool)\n",
    "    df_2plot['has_central_body'] = has_central_body.astype(bool)\n",
    "    df_2plot['has_human_body'] = has_human_body.astype(bool)\n",
    "    df_2plot['has_central_human_body'] = (has_human_body*has_central_body).astype(bool)\n",
    "\n",
    "    df_2plot['has_living'] = (has_body + is_face).astype(bool)\n",
    "    df_2plot['has_central_living'] = ((has_body*has_central_body) + (is_face*is_central_face)).astype(bool)\n",
    "\n",
    "    # levels: central living (body or face): human (3), nh_mammal (2) or something else (1)\n",
    "    centr_human = ((has_human_body*has_central_body) + (is_human_face*is_central_face)).astype(bool)\n",
    "    centr_mammal = ((has_nh_mammal_body*has_central_body) + (is_nh_mammal_face*is_central_face)).astype(bool)\n",
    "    df_2plot['clpt'] = (df_2plot['has_central_living'].to_numpy() + (2*centr_human) + centr_mammal).astype(int)\n",
    "    df_2plot['clpt'] = df_2plot.apply(lambda row: cap_vals(row, 'clpt', 3), axis=1)\n",
    "    df_2plot['central_living_per_type'] = df_2plot.apply(lambda row: label_clt(row), axis=1)\n",
    "\n",
    "    # levels: central body: human (3), nh_mammal (2) or something else (1)\n",
    "    df_2plot['cbpt'] = (has_central_body + (2*(has_central_body*has_human_body)) + (has_central_body*has_nh_mammal_body)).astype(int)\n",
    "    df_2plot['cbpt'] = df_2plot.apply(lambda row: cap_vals(row, 'cbpt', 3), axis=1)\n",
    "    df_2plot['central_body_per_type'] = df_2plot.apply(lambda row: label_cbt(row), axis=1)\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Scene stuff\n",
    "    \"\"\"    \n",
    "    is_lone_object = np.array([img_details[img_idx[x]]['manual_lone_object'] for x in beta_idx])\n",
    "    is_scene = np.array([img_details[img_idx[x]]['manual_scene'] for x in beta_idx])\n",
    "    had_bcground = np.array([img_details[img_idx[x]]['manual_rich_background'] for x in beta_idx])\n",
    "\n",
    "    df_2plot['is_scene'] = is_scene.astype(bool)\n",
    "    df_2plot['has_bckground'] = had_bcground.astype(bool)\n",
    "    df_2plot['background_or_scene'] = (had_bcground + is_scene).astype(bool)\n",
    "\n",
    "    # levels: is lone object (0), object (1), bckground (2) or scene (3)\n",
    "    df_2plot['bkpt'] = (np.ones(df_2plot.shape[0]) + had_bcground + 2*(is_scene) - is_lone_object).astype(int)\n",
    "    df_2plot['bkpt'] = df_2plot.apply(lambda row: cap_vals(row, 'bkpt', 3), axis=1)\n",
    "    df_2plot['background_per_type'] = df_2plot.apply(lambda row: label_bkpt(row), axis=1)\n",
    "\n",
    "    df_2plot['rank'] = np.array(df_2plot.index + 1).astype(int)\n",
    "\n",
    "    return df_2plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88aa68cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define paths and parameters\n",
    "\"\"\"\n",
    "# Set paths\n",
    "data_file_path = Path(\"../../THINGS/things.glmsingle\").resolve()\n",
    "fig_save_path = Path(\"../figures\").resolve()\n",
    "\n",
    "# Define color options\n",
    "hue_options = {\n",
    "    'annotation-face': ('central_face_per_type', {'1. human face':'xkcd:burnt red', '2. mammal face':'xkcd:bright orange', '3. other face':'xkcd:apple green', '4. no face':\"xkcd:baby blue\"}),\n",
    "    'annotation-body': ('central_body_per_type', {'1. human body':'xkcd:burnt red', '2. mammal body':'xkcd:bright orange', '3. other living body':'xkcd:apple green', '4. no living body':'xkcd:baby blue'}),\n",
    "    'annotation-scene': ('background_per_type', {'1. scene':'xkcd:burnt red', '2. rich background':'xkcd:bright orange', '3. minimal background':'xkcd:apple green', '4. no background':\"xkcd:baby blue\"}),\n",
    "}\n",
    "\n",
    "# Load image labels and annotations\n",
    "with open(f\"{data_file_path}/task-things_imgAnnotations.json\", \"r\") as f:\n",
    "    image_details = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d33e0eb",
   "metadata": {},
   "source": [
    "## Code to generate beta rankings from Figure 5\n",
    "\n",
    "These plots feature image-wise (averaged over 3 repetitions) or trial-wise normalized (z-scored) betas, ranked from largest (left) to smallest (right), and color-coded to reflect image content annotations (e.g., the presence or absence of faces, scenary or body parts).\n",
    "\n",
    "**In Figure 5 from the datapaper**, rankings are shown for image-wise betas from the one voxel with the highest noise ceiling within an ROI mask derived from the fLoc task (ROIs = fusiform face area (FFA), parahippocampal place area (PPA) and extrastriate body area (EBA)). \n",
    "\n",
    "To re-create these plots, set ``top_voxel = True`` and ``per_image = True`` in the options below.\n",
    "\n",
    "The current notebook can also plot **beta rankings from single trials** (set ``per_image = False``). \n",
    "\n",
    "Both trial-wise and image-wise beta rankings can be based on betas from the **one voxel** with the highest noise ceiling (``top_voxel = True``) within an ROI, or from **betas averaged across the 50 voxels** with the highest noise ceilings within an ROI (``top_voxel = False``). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0378165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "If True, ranks betas from the ROI's single voxel with the highest noise ceiling.\n",
    "\n",
    "If False, averages betas across the 50 ROI voxels with the highest noise ceilings,\n",
    "and then rank these mean betas. \n",
    "\n",
    "Set to True to re-create Figure 5 from the datapaper.\n",
    "\"\"\"\n",
    "top_voxel = True\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "If True, ranks betas averaged per image (over 3 repetitions) within each voxel.\n",
    "Excludes images with any blank answer and images with fewer than 3 repetitions.\n",
    "\n",
    "If False, ranks trial-wise betas (exclude trials with blank answers).\n",
    "\n",
    "Set to True to re-create Figure 5 from the datapaper.\n",
    "\"\"\"\n",
    "per_image = True\n",
    "\n",
    "\n",
    "# set to True to export .png file\n",
    "save_fig = False\n",
    "\n",
    "# Specify ROI between: fusiform face area (FFA), extrastriate body area (EBA), and parahipp. place area (PPA)\n",
    "roi = 'face_roi-FFA'  # 'face_roi-FFA', 'body_roi-EBA', 'scene_roi-PPA'\n",
    "\n",
    "\n",
    "# Select ranked betas' color-coded annotation among the 3 choices below:\n",
    "hue_choice = 'annotation-face'  # 'annotation-face', 'annotation-body', 'annotation-scene'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfe85161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. human face, color:'xkcd:burnt red'\n",
      "2. mammal face, color:'xkcd:bright orange'\n",
      "3. other face, color:'xkcd:apple green'\n",
      "4. no face, color:'xkcd:baby blue'\n",
      "sub-01\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x108 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-02\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x108 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-03\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x108 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-06\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x108 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generate the beta ranking plots\n",
    "\n",
    "Warnings:\n",
    "- each plot can take several minutes to generate due to the large number of betas \n",
    "  (especially if per_image = False)\n",
    "- high image resolution is needed for patterns to appear clearly.\n",
    "- Saved .png images look much sharper and fuller than the ones displayed in this notebook\n",
    "  (notebook patterns can appear incomplete/patchy)\n",
    "\"\"\"\n",
    "\n",
    "SMALL_SIZE = 10\n",
    "BIGGER_SIZE = 20\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)  # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)  # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=SMALL_SIZE)  # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)  # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)  # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=BIGGER_SIZE)  # legend fontsize\n",
    "plt.rc('figure', titlesize=SMALL_SIZE)  # fontsize of the figure title\n",
    "\n",
    "\n",
    "desc = \"perImage\" if per_image else \"perTrial\"\n",
    "hue, palette = hue_options[hue_choice]\n",
    "\n",
    "for k, v in palette.items():\n",
    "    print(f\"{k}, color:'{v}'\")\n",
    "    \n",
    "for s in ['01', '02', '03', '06']:\n",
    "    betas = np.load(\n",
    "        glob.glob(\n",
    "            f\"{data_file_path}/sub-{s}/descriptive/sub-{s}_task-things_space-T1w_contrast-{roi}_*\"\n",
    "            f\"_stats-betas_desc-{desc}_statseries.npy\"\n",
    "        )[0], allow_pickle=True)\n",
    "\n",
    "    imgIdx = np.load(\n",
    "        f\"{data_file_path}/sub-{s}/descriptive/sub-{s}_task-things_desc-{desc}_labels.npy\",\n",
    "        allow_pickle=True)\n",
    "\n",
    "    noiseCeil = np.load(\n",
    "        glob.glob(\n",
    "            f\"{data_file_path}/sub-{s}/descriptive/sub-{s}_task-things_space-T1w_contrast-{roi}_*\"\n",
    "            f\"_stats-noiseCeilings_desc-{desc}_statseries.npy\"\n",
    "        )[0], allow_pickle=True)\n",
    "\n",
    "\n",
    "    if top_voxel:\n",
    "        \"\"\"\n",
    "        Rank betas from single voxel with highest noise ceiling within ROI mask\n",
    "        \"\"\"    \n",
    "        # get top voxel's betas\n",
    "        top_idx = np.argmax(noiseCeil)\n",
    "        select_betas = betas[:, top_idx] \n",
    "        nvox = \"nvox-1\"\n",
    "\n",
    "    else:\n",
    "        \"\"\"\n",
    "        Average betas from all (n=50) ROI voxels and rank mean betas\n",
    "        \"\"\"    \n",
    "        select_betas = np.mean(betas, axis=1)\n",
    "        nvox = f\"nvox-{betas.shape[1]}\"\n",
    "\n",
    "\n",
    "    # sort selected betas from larger to smaller beta\n",
    "    betas_idx = np.argsort(select_betas, axis=0)[::-1]  \n",
    "    ranked_betas = select_betas[betas_idx]\n",
    "\n",
    "    # get corresponding betas' image annotations\n",
    "    df_annotations = generate_data(betas_idx, imgIdx, ranked_betas, image_details)\n",
    "\n",
    "    plt.figure(figsize=(5, 1.5))\n",
    "        \n",
    "    sns.barplot(\n",
    "        data=df_annotations,\n",
    "        x='rank',\n",
    "        y='betas',\n",
    "        hue=hue,\n",
    "        palette=palette,\n",
    "        dodge=False,\n",
    "    )\n",
    "\n",
    "    plt.xticks(ticks=[])\n",
    "    plt.ylabel('')\n",
    "    plt.xlabel('')\n",
    "\n",
    "    plt.legend().remove()\n",
    "\n",
    "    if save_fig:\n",
    "        Path(f\"{fig_save_path}/b_rankings\").mkdir(parents=True, exist_ok=True)\n",
    "        rname = roi.split('_')[-1]        \n",
    "        plt.savefig(f'{fig_save_path}/b_rankings/sub-{s}_{rname}_{hue_choice}_{nvox}_{desc}_bRank.png', dpi=1000) \n",
    "    \n",
    "    print(f\"sub-{s}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fdec15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
